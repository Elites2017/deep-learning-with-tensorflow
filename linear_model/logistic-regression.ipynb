{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Linear Model [Logistic Regression]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cached data.\n",
      "Took 0:00:00.277439\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "save_dir = '../saved/logistic-regression'\n",
    "data_dir = '../datasets/MNIST'\n",
    "saved_data = os.path.join(save_dir, f'data/{os.path.basename(data_dir)}.pkl')\n",
    "\n",
    "if not os.path.isfile(saved_data):\n",
    "    start = dt.now()\n",
    "    data = input_data.read_data_sets('../datasets/MNIST/', one_hot=True)\n",
    "    print(f'Took {dt.now() - start}')\n",
    "    if not os.path.exists(os.path.dirname(saved_data)):\n",
    "        os.makedirs(os.path.dirname(saved_data))\n",
    "    pickle.dump(file=open(saved_data, 'wb'), obj=data)\n",
    "    \n",
    "    print('\\nCached data for future use.')\n",
    "else:\n",
    "    start = dt.now()\n",
    "    data = pickle.load(file=open(saved_data, 'rb'))\n",
    "    print('Loaded cached data.')\n",
    "    print(f'Took {dt.now() - start}')\n",
    "del start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data   = 55,000\n",
      "Testing data    = 10,000\n",
      "Validation data =  5,000\n"
     ]
    }
   ],
   "source": [
    "print('Training data   = {:,}'.format(len(data.train.labels)))\n",
    "print('Testing data    = {:,}'.format(len(data.test.labels)))\n",
    "print('Validation data =  {:,}'.format(len(data.validation.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "image_size = 28\n",
    "image_shape = (image_size, image_size)\n",
    "image_size_flat = image_size * image_size\n",
    "num_classes = 10\n",
    "\n",
    "# Training\n",
    "save_step = 500\n",
    "num_iter = 0\n",
    "val_batch = 50\n",
    "test_batch = 70\n",
    "train_batch = 200\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Building the _Computational Graph_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Placeholder variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, image_size_flat])\n",
    "y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "y_cls = tf.argmax(y, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Trainable variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.truncated_normal(shape=[image_size_flat, num_classes]))\n",
    "b = tf.Variable(tf.zeros(shape=[num_classes]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logits = tf.add(tf.matmul(X, W), b)\n",
    "y_pred = tf.nn.softmax(logits)\n",
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Cost function and Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xentropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "# Optimizer\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_step = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Performance measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "correct = tf.equal(y_pred_cls, y_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Running the Computational Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Define `tf.Session`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### _initializing model/global variables_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def init():\n",
    "    global num_iter\n",
    "    __init = tf.global_variables_initializer()\n",
    "    sess.run(__init)\n",
    "    num_iter = 0\n",
    "init()  # Initialize to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tensorboard_dir = os.path.join(save_dir, 'tensorboard')\n",
    "logdir = os.path.join(tensorboard_dir, 'log')\n",
    "\n",
    "model_dir = os.path.join(save_dir, 'models')\n",
    "model_path = os.path.join(model_dir, 'model.ckpt')\n",
    "\n",
    "# Histograms\n",
    "tf.summary.histogram('W', values=W, family='params')\n",
    "tf.summary.histogram('b', values=b, family='params')\n",
    "# Scalars\n",
    "tf.summary.scalar('loss', tensor=loss, family='evaluation')\n",
    "tf.summary.scalar('accuracy', tensor=accuracy, family='evaluation')\n",
    "# merged...\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "# Savers and writers\n",
    "saver = tf.train.Saver()\n",
    "writer = tf.summary.FileWriter(logdir=logdir, graph = sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maybe restore checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Attempting to restore last checkpoint\n",
      "INFO:tensorflow:Restoring parameters from ../saved/logistic-regression/models/model.ckpt-20903\n",
      "INFO: Successfully restored last checkpoint ../saved/logistic-regression/models/model.ckpt-20903\n"
     ]
    }
   ],
   "source": [
    "if tf.gfile.Exists(model_dir):\n",
    "    try:\n",
    "        print('INFO: Attempting to restore last checkpoint')\n",
    "        last_ckpt = tf.train.latest_checkpoint(model_dir)\n",
    "        saver.restore(sess=sess, save_path=last_ckpt)\n",
    "        print(f'INFO: Successfully restored last checkpoint {last_ckpt}')\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(f'ERR: Could not restore checkpoint. {e}')\n",
    "        sys.stderr.flush()\n",
    "else:\n",
    "    tf.gfile.MakeDirs(model_dir)\n",
    "    print(f'INFO: Created checkpoint dir @ {model_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Define Some Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### _Train the model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(iterations=1000):\n",
    "    global num_iter\n",
    "    start = dt.now()\n",
    "    for _ in range(iterations):\n",
    "        # Increment the iteration counter.\n",
    "        num_iter += 1\n",
    "        # Get batches\n",
    "        X_batch, y_batch = data.train.next_batch(train_batch)\n",
    "        feed_dict = {X: X_batch, y: y_batch}\n",
    "        _, i_global = sess.run([train_step, global_step], feed_dict=feed_dict)\n",
    "        if num_iter % save_step == 0:\n",
    "            saver.save(sess=sess, save_path=model_path, global_step=global_step)\n",
    "            summary = sess.run(merged, feed_dict=feed_dict)\n",
    "            writer.add_summary(summary, global_step=i_global)\n",
    "        sys.stdout.write(f'\\rIter: {num_iter:,}\\tGlobal iter: {i_global:,}'\n",
    "                         f'\\tTime taken: {dt.now() - start}')\n",
    "    print()\n",
    "    print(f\"{80*'='}\")\n",
    "    print(f'\\tCompleted {num_iter:,} iterations.')\n",
    "    print(f\"{80*'='}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Run accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def score(test=True, validation=False, use_batch=True):\n",
    "    print(80*'=')\n",
    "    print('Accuracy after {:,} iterations'.format(num_iter))\n",
    "    feed_dict = None\n",
    "    if test:\n",
    "        if use_batch:\n",
    "            X_batch, y_batch = data.test.next_batch(test_batch)\n",
    "            feed_dict = {X: X_batch, y: y_batch}\n",
    "        else:\n",
    "            feed_dict = {X: data.test.images, y: data.test.labels}\n",
    "        acc = sess.run(accuracy, feed_dict=feed_dict)\n",
    "        print('Accuracy on test set: {:.02%}'.format(acc))\n",
    "    if validation:\n",
    "        if use_batch:\n",
    "            X_batch, y_batch = data.validation.next_batch(val_batch)\n",
    "            feed_dict = {X: X_batch, y: y_batch}\n",
    "        else:\n",
    "            feed_dict = {X: data.validation.images, y: data.validation.labels}\n",
    "        acc = sess.run(accuracy, feed_dict=feed_dict)\n",
    "        print('Accuracy on validation set: {:.02%}'.format(acc))\n",
    "    print(80*'=')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Iter: 1\tGlobal iter: 20,904\tTime taken: 0:00:00.158208\r",
      "Iter: 2\tGlobal iter: 20,905\tTime taken: 0:00:00.160044\r",
      "Iter: 3\tGlobal iter: 20,906\tTime taken: 0:00:00.161762\r",
      "Iter: 4\tGlobal iter: 20,907\tTime taken: 0:00:00.163573\r",
      "Iter: 5\tGlobal iter: 20,908\tTime taken: 0:00:00.165358\r",
      "Iter: 6\tGlobal iter: 20,909\tTime taken: 0:00:00.167035\r",
      "Iter: 7\tGlobal iter: 20,910\tTime taken: 0:00:00.168846\r",
      "Iter: 8\tGlobal iter: 20,911\tTime taken: 0:00:00.170613\r",
      "Iter: 9\tGlobal iter: 20,912\tTime taken: 0:00:00.172504\r",
      "Iter: 10\tGlobal iter: 20,913\tTime taken: 0:00:00.174387\n",
      "================================================================================\n",
      "\tCompleted 10 iterations.\n",
      "================================================================================\n",
      "================================================================================\n",
      "Accuracy after 10 iterations\n",
      "Accuracy on test set: 92.18%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "train(iterations=10)\n",
    "score(test=True, use_batch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\tGlobal iter: 21,003\tTime taken: 0:00:00.219556\n",
      "================================================================================\n",
      "\tCompleted 100 iterations.\n",
      "================================================================================\n",
      "================================================================================\n",
      "Accuracy after 100 iterations\n",
      "Accuracy on test set: 92.17%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "train(iterations=90)\n",
    "score(test=True, use_batch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1,000\tGlobal iter: 21,903\tTime taken: 0:00:02.654562\n",
      "================================================================================\n",
      "\tCompleted 1,000 iterations.\n",
      "================================================================================\n",
      "================================================================================\n",
      "Accuracy after 1,000 iterations\n",
      "Accuracy on test set: 97.14%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "train(iterations=900)\n",
    "score(test=True, use_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 10,000\tGlobal iter: 30,903\tTime taken: 0:00:22.784164\n",
      "================================================================================\n",
      "\tCompleted 10,000 iterations.\n",
      "================================================================================\n",
      "================================================================================\n",
      "Accuracy after 10,000 iterations\n",
      "Accuracy on test set: 90.00%\n",
      "Accuracy on validation set: 92.00%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "train(iterations=9000)\n",
    "score(test=True, validation=True, use_batch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear cached files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Clear saved mnist `data`\n",
    "shutil.rmtree(os.path.dirname(saved_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
