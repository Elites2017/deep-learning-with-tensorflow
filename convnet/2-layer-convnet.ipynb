{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2-Layer Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cached data.\n",
      "Took 0:00:00.278913\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "save_dir = '../saved/convnet/2-layers'\n",
    "data_dir = '../datasets/MNIST'\n",
    "saved_data = os.path.join(save_dir, f'data/{os.path.basename(data_dir)}.pkl')\n",
    "\n",
    "if not os.path.isfile(saved_data):\n",
    "    start = dt.now()\n",
    "    data = input_data.read_data_sets(data_dir, one_hot=True)\n",
    "    print(f'Took {dt.now() - start}')\n",
    "    if not os.path.exists(os.path.dirname(saved_data)):\n",
    "        os.makedirs(os.path.dirname(saved_data))\n",
    "    pickle.dump(file=open(saved_data, 'wb'), obj=data)\n",
    "    \n",
    "    print('\\nCached data for future use.')\n",
    "else:\n",
    "    start = dt.now()\n",
    "    data = pickle.load(file=open(saved_data, 'rb'))\n",
    "    print('Loaded cached data.')\n",
    "    print(f'Took {dt.now() - start}')\n",
    "\n",
    "# free memory\n",
    "del start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set    = 55,000\n",
      "Testing set     = 10,000\n",
      "Validation set  =  5,000\n"
     ]
    }
   ],
   "source": [
    "print('Training set    = {:,}'.format(len(data.train.labels)))\n",
    "print('Testing set     = {:,}'.format(len(data.test.labels)))\n",
    "print('Validation set  =  {:,}'.format(len(data.validation.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data dimension\n",
    "image_size = 28\n",
    "image_channel = 1\n",
    "image_shape = (image_size, image_size, image_channel)\n",
    "image_shape_flat = image_size * image_size\n",
    "num_classes = 10\n",
    "\n",
    "# Network\n",
    "filter_size = 5\n",
    "filter_1 = 32\n",
    "filter_2 = 64\n",
    "fc_size = 256\n",
    "dropout = 0.8\n",
    "\n",
    "# Training\n",
    "train_batch = 100\n",
    "test_batch = 50\n",
    "val_batch = 25\n",
    "learning_rate = 1e-2\n",
    "n_iters = 0  # Total number of completed optimization iterations\n",
    "save_interval = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### `weights` and `biases`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def weight(shape):\n",
    "    initial = tf.truncated_normal(shape=shape, stddev=0.5, mean=0)\n",
    "    return tf.Variable(initial, name='weight')\n",
    "\n",
    "\n",
    "def bias(shape):\n",
    "    initial = tf.zeros(shape=[shape])\n",
    "    return tf.Variable(initial, name='bias')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### `convolution` and `pooling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv2d(X, W):\n",
    "    return tf.nn.conv2d(X, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool(X):\n",
    "    return tf.nn.max_pool(X, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### `conv`, `fully connected` & `flatten` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(incoming, filter_size, out_units, activation=tf.nn.relu):\n",
    "    in_units = incoming.get_shape()[-1].value\n",
    "    # Weights and biases\n",
    "    W = weight(shape=[filter_size, filter_size, in_units, out_units])\n",
    "    b = bias(shape=out_units)\n",
    "    # convolution and add bias\n",
    "    layer = conv2d(incoming, W) + b\n",
    "    # max pooling\n",
    "    layer = max_pool(layer)\n",
    "    # apply activation function\n",
    "    if activation:\n",
    "        layer = activation(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def fully_connected(incoming, units, activation=tf.nn.relu, dropout=None):\n",
    "    in_units = incoming.get_shape()[-1].value\n",
    "    # parameters\n",
    "    W = weight(shape=[in_units, units])\n",
    "    b = bias(shape=units)\n",
    "    # matrix multiplicaiton\n",
    "    layer = tf.matmul(incoming, W) + b\n",
    "    # add dropout\n",
    "    if dropout is not None:\n",
    "        layer = tf.nn.dropout(layer, keep_prob=dropout)\n",
    "    # apply activation\n",
    "    if activation:\n",
    "        layer = activation(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def flatten(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = np.array(layer_shape[1:4], dtype=int).prod()\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    return layer_flat, num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Building the Computational Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Placeholder variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, image_shape_flat])\n",
    "y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Building the `convnet`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(?, 28, 28, 1) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_image = tf.reshape(X, [-1, image_size, image_size, image_channel])\n",
    "y_true = tf.argmax(y, axis=1)\n",
    "X_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Input Layer »» Hidden Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu:0\", shape=(?, 14, 14, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "hidden1 = conv_layer(X_image, filter_size, filter_1)\n",
    "\n",
    "print(f'{hidden1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Hidden Layer 1 »» Hidden Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "hidden2 = conv_layer(hidden1, filter_size, filter_2)\n",
    "\n",
    "print(f'{hidden2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Flatten Hidden Layer 2 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_1:0\", shape=(?, 3136), dtype=float32)\tFeatures: 3,136\n"
     ]
    }
   ],
   "source": [
    "hidden2_flat, num_features = flatten(hidden2)\n",
    "\n",
    "print(f'{hidden2_flat}\\tFeatures: {num_features:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### HIdden Layer 2 »» Fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_2:0\", shape=(?, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "fc_layer = fully_connected(hidden2_flat, units=fc_size, dropout=keep_prob)\n",
    "\n",
    "print(f'{fc_layer}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Fully connected Layer »» Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: Tensor(\"add_3:0\", shape=(?, 10), dtype=float32)\n",
      "y_pred_true: Tensor(\"ArgMax_1:0\", shape=(?,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "logits = fully_connected(fc_layer, units=num_classes, activation=None)\n",
    "y_pred = tf.nn.softmax(logits)\n",
    "y_pred_true = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "print(f'logits: {logits}\\ny_pred_true: {y_pred_true}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xentropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "cost = tf.reduce_mean(xentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_step = optimizer.minimize(cost, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Evaluate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "correct = tf.equal(y_true, y_pred_true)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "print(f'{accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Running the Computional Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### tensorflow's `Session`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# tensorboard logging\n",
    "tensorboard_dir = os.path.join(save_dir, 'tensorboard')\n",
    "logdir = os.path.join(tensorboard_dir, 'log')\n",
    "# Pre-trained model\n",
    "model_dir = os.path.join(save_dir, 'models')\n",
    "model_file = os.path.join(model_dir, 'model.ckpt')\n",
    "\n",
    "# Summary\n",
    "tf.summary.scalar('cost', cost)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "# writer and saver\n",
    "saver = tf.train.Saver()\n",
    "writer = tf.summary.FileWriter(logdir=logdir, graph=sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Restore last checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Attempting to restore last checkpoint.\n",
      "INFO:tensorflow:Restoring parameters from ../saved/convnet/2-layers/models/model.ckpt-11000\n",
      "SUCCESS: Checkpoint restored @ ../saved/convnet/2-layers/models/model.ckpt-11000\n"
     ]
    }
   ],
   "source": [
    "if tf.gfile.Exists(model_dir):\n",
    "    # noinspection PyBroadException\n",
    "    try:\n",
    "        print('INFO: Attempting to restore last checkpoint.')\n",
    "        last_ckpt = tf.train.latest_checkpoint(model_dir)\n",
    "        saver.restore(sess=sess, save_path=last_ckpt)\n",
    "        print(f'SUCCESS: Checkpoint restored @ {last_ckpt}')\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(f'ERR: Could not load checkpoint. {e}')\n",
    "        sys.stderr.flush()\n",
    "else:\n",
    "    tf.gfile.MakeDirs(model_dir)\n",
    "    print(f'INFO: Checkpoint folder created - {model_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Perform Optimzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(iterations=1000):\n",
    "    global n_iters\n",
    "    start = dt.now()\n",
    "    for _ in range(iterations):\n",
    "        n_iters += 1\n",
    "        X_batch, y_batch = data.train.next_batch(train_batch)\n",
    "        feed_dict = {X: X_batch, y: y_batch, keep_prob: dropout}\n",
    "        _, i_global = sess.run([train_step, global_step], feed_dict=feed_dict)\n",
    "        # Save checkpoint and summarize tensorboard\n",
    "        if n_iters % save_interval == 0:\n",
    "            summary = sess.run(merged, feed_dict=feed_dict)\n",
    "            writer.add_summary(summary, global_step=i_global)\n",
    "            saver.save(sess=sess, save_path=model_file, global_step=global_step)\n",
    "        # Log progress\n",
    "        sys.stdout.write(f'\\rIter: {n_iters:,}\\tGlobal step: {i_global:,}'\n",
    "                         f'\\tTime taken: {dt.now() - start}')\n",
    "        sys.stdout.flush()\n",
    "    print(f\"\\n{80*'='}\")\n",
    "    print(f'\\tCompleted {n_iters:,} iterations.')\n",
    "    print(80*'=')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Evaluate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def score(test=True, validation=False, use_batch=True):\n",
    "    print(80 * '=')\n",
    "    print('Accuracy after {:,} iterations'.format(n_iters))\n",
    "    if test:\n",
    "        if use_batch:\n",
    "            X_batch, y_batch = data.test.next_batch(test_batch)\n",
    "            feed_dict = {X: X_batch, y: y_batch, keep_prob: dropout}\n",
    "        else:\n",
    "            feed_dict = {X: data.test.images, y: data.test.labels, keep_prob: dropout}\n",
    "        acc = sess.run(accuracy, feed_dict=feed_dict)\n",
    "        print('Accuracy on test set: {:.02%}'.format(acc))\n",
    "    if validation:\n",
    "        if use_batch:\n",
    "            X_batch, y_batch = data.validation.next_batch(val_batch)\n",
    "            feed_dict = {X: X_batch, y: y_batch, keep_prob: dropout}\n",
    "        else:\n",
    "            feed_dict = {X: data.validation.images, y: data.validation.labels, keep_prob: dropout}\n",
    "        acc = sess.run(accuracy, feed_dict=feed_dict)\n",
    "        print('Accuracy on validation set: {:.02%}'.format(acc))\n",
    "    print(80 * '=')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training the Network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 10\tGlobal step: 11,010\tTime taken: 0:00:03.280711\n",
      "================================================================================\n",
      "\tCompleted 10 iterations.\n",
      "================================================================================\n",
      "================================================================================\n",
      "Accuracy after 10 iterations\n",
      "Accuracy on test set: 75.35%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "train(iterations=10)\n",
    "score(test=True, use_batch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\tGlobal step: 11,100\tTime taken: 0:00:25.704833\n",
      "================================================================================\n",
      "\tCompleted 100 iterations.\n",
      "================================================================================\n",
      "================================================================================\n",
      "Accuracy after 100 iterations\n",
      "Accuracy on test set: 80.96%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "train(iterations=90)\n",
    "score(test=True, use_batch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1,000\tGlobal step: 12,000\tTime taken: 0:04:03.909594\n",
      "================================================================================\n",
      "\tCompleted 1,000 iterations.\n",
      "================================================================================\n",
      "================================================================================\n",
      "Accuracy after 1,000 iterations\n",
      "Accuracy on test set: 86.00%\n",
      "Accuracy on validation set: 80.00%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "train(iterations=900)\n",
    "score(test=True, validation=True, use_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4,101\tGlobal step: 15,101\tTime taken: 0:16:12.401926"
     ]
    }
   ],
   "source": [
    "train(iterations=9000)\n",
    "score(test=True, validation=True, use_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Clear saved mnist `data`\n",
    "shutil.rmtree(os.path.dirname(saved_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
